{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76309e9a",
   "metadata": {},
   "source": [
    "# Estimating “bias currents” from the affine model\n",
    "\n",
    "The affine model writes the field as  \n",
    "$$\n",
    "\\mathbf{b}(\\mathbf{p}, \\mathbf{i}) = \\mathcal{A}_b(\\mathbf{p})\\,\\mathbf{i} + \\mathbf{b}_0(\\mathbf{p}),\n",
    "$$  \n",
    "\n",
    "---\n",
    "\n",
    "### Stacking several positions\n",
    "\n",
    "Choose $k$ positions $\\mathbf{p}_1,\\dots,\\mathbf{p}_k$ and evaluate the model in each, giving for each position $\\mathbf{p}_i$ a field actuation matrix $\\mathcal{A}_{b,i}$ and field offset $\\mathbf{b}_{0,i}$.\n",
    "\n",
    "Stack them:\n",
    "$$\n",
    "\\mathcal{A}_{b,\\text{stack}} =\n",
    "\\begin{bmatrix}\n",
    "\\mathcal{A}_{b,1}\\\\\n",
    "\\mathcal{A}_{b,2}\\\\\n",
    "\\vdots\\\\\n",
    "\\mathcal{A}_{b,k}\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^{3k\\times 8},\\qquad\n",
    "\\mathbf{b}_{0,\\text{stack}} =\n",
    "\\begin{bmatrix}\n",
    "\\mathbf b_1\\\\\n",
    "\\mathbf b_2\\\\\n",
    "\\vdots\\\\\n",
    "\\mathbf b_k\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb R^{3k}.\n",
    "$$\n",
    "\n",
    "We want one current vector $\\mathbf{i}_{\\text{equiv}}$ such that\n",
    "$$\n",
    "\\mathcal{A}_{b,\\text{stack}} \\,\\mathbf{i}_{\\text{equiv}} \\approx \\mathbf{b}_{0, \\text{stack}}.\n",
    "$$\n",
    "\n",
    "This is a least-squares problem. If $\\mathcal{A}_{b,\\text{stack}}$ has full column rank (rank $8$), the least-squares solution is\n",
    "$$\n",
    "\\mathbf{i}_{\\text{equiv}} = \\mathcal{A}_{b,\\text{stack}}^{\\dagger}\\,\\mathbf{b}_{0,\\text{stack}},\n",
    "$$\n",
    "where $\\mathcal{A}_{b,\\text{stack}}^{\\dagger}$ is the Moore–Penrose pseudoinverse.\n",
    "\n",
    "Interpretation: $\\mathbf{i}_{\\text{equiv}}$ are the equivalent currents that best reproduce the learned bias field across all sampled positions.\n",
    "\n",
    "---\n",
    "\n",
    "### Rank, conditioning, and residual\n",
    "\n",
    "We choose more positions until $\\mathcal{A}_{b,\\text{stack}}$  \n",
    "\n",
    "- has rank $8$ (full column rank), and  \n",
    "- has condition number $\\kappa(\\mathcal{A}_{b,\\text{stack}})$ below some threshold,\n",
    "\n",
    "so that the pseudoinverse and the inferred currents are numerically stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a41de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "base_dir = os.path.dirname(parent_dir)\n",
    "data_dir = base_dir + \"/data/octomag_data/split_dataset\"\n",
    "src_dir = base_dir + \"/src\"\n",
    "params_dir = parent_dir + \"/training/params\"\n",
    "\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "from calibration import MPEM, MPEM_AVAILABLE, ActuationNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_path = data_dir + \"/training_data.pkl\"\n",
    "data = pd.read_pickle(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load affine model\n",
    "model_path = params_dir + \"/ActuationNet_100_512x512x512.pt\"\n",
    "model = ActuationNet.load_from(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749a78f7",
   "metadata": {},
   "source": [
    "## Notation alert:\n",
    "\n",
    "In the following code we use $J$ (as in Jacobian) for the field actuation matrix $\\mathcal{A}_b$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce72a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_well_conditioned_stack(\n",
    "    data,\n",
    "    affine_model,\n",
    "    max_num_samples=50,\n",
    "    cond_threshold=5,\n",
    "    min_samples=3,\n",
    "    svd_tol=1e-8,\n",
    "    seed=0,\n",
    "    verbose = True\n",
    "):\n",
    "    \"\"\"\n",
    "    Incrementally stack J (3x8) from AffineActuationNet evaluated at positions\n",
    "    sampled from `data` until:\n",
    "\n",
    "      - rank(J_stack) == 8 (full column rank), and\n",
    "      - cond(J_stack) <= cond_threshold\n",
    "\n",
    "    or we hit max_num_samples.\n",
    "\n",
    "    J and b are converted to *physical units* if `normalization_params`\n",
    "    (with keys \"mean\" and \"std\") is provided.\n",
    "\n",
    "    Returns:\n",
    "        J_pinv_final   : np.ndarray of shape (8, 3*k_used) or None if never valid\n",
    "        cond_final     : float (condition number) or np.inf\n",
    "        k_used         : int, number of samples used for best_cond\n",
    "        J_stack_final  : np.ndarray of shape (3*k_used, 8) or None\n",
    "        b_stack_final  : np.ndarray of shape (3*k_used,) or None\n",
    "    \"\"\"\n",
    "    affine_model.eval()\n",
    "    device = next(affine_model.parameters()).device\n",
    "\n",
    "    N_rows = len(data)\n",
    "    max_num_samples = min(max_num_samples, N_rows)\n",
    "\n",
    "    rng = np.random.default_rng(seed) if type(seed) == int else seed\n",
    "    sample_indices = rng.choice(N_rows, size=max_num_samples, replace=False)\n",
    "\n",
    "    J_blocks = []  # list of (3, 8)\n",
    "    b_blocks = []  # list of (3,)\n",
    "\n",
    "    best_cond = np.inf\n",
    "    best_J_pinv = None\n",
    "    best_k = 0\n",
    "\n",
    "    n_cols = 8  # J has shape (3, 8)\n",
    "\n",
    "    for k, idx in enumerate(sample_indices, start=1):\n",
    "        # position from DataFrame row\n",
    "        row = data.iloc[idx]\n",
    "        pos_np = row[[\"x\", \"y\", \"z\"]].to_numpy(dtype=np.float32)  # (3,)\n",
    "        pos_t  = torch.tensor(pos_np, dtype=torch.float32, device=device).unsqueeze(0)  # (1, 3)\n",
    "        with torch.no_grad():\n",
    "            J_batch, b_batch = affine_model(pos_t, currents=None)  # (1,3,8), (1,3)\n",
    "\n",
    "        J_phys = J_batch[0].cpu().numpy()  # (3, 8)\n",
    "        b_phys = b_batch[0].cpu().numpy()  # (3,)\n",
    "\n",
    "        J_blocks.append(J_phys)\n",
    "        b_blocks.append(b_phys)\n",
    "\n",
    "        # stack so far\n",
    "        J_stack = np.vstack(J_blocks)  # (3*k, 8)\n",
    "        n_rows = J_stack.shape[0]\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"After {k:2d} samples (row {idx}), J_stack shape = {J_stack.shape}\")\n",
    "\n",
    "        # Don't check conditioning until we have enough rows & samples\n",
    "        if n_rows < n_cols or k < min_samples:\n",
    "            continue\n",
    "\n",
    "        # SVD, rank, and condition number\n",
    "        U, S, Vh = np.linalg.svd(J_stack, full_matrices=False)\n",
    "\n",
    "        # numerical rank\n",
    "        rank = np.sum(S > svd_tol)\n",
    "\n",
    "        if rank < n_cols:\n",
    "            cond = np.inf\n",
    "            if verbose:\n",
    "                print(f\"  rank(J_stack) = {rank} < {n_cols} -> ill-conditioned (cond = ∞)\")\n",
    "        else:\n",
    "            sigma_max = S[0]\n",
    "            sigma_min = S[rank - 1]\n",
    "            cond = sigma_max / sigma_min\n",
    "            if verbose:\n",
    "                print(f\"  rank(J_stack) = {rank}, cond(J_stack) = {cond:.3e}\")\n",
    "\n",
    "        # track best (smallest) cond so far if it's finite and full rank\n",
    "        if np.isfinite(cond) and rank == n_cols and cond < best_cond:\n",
    "            best_cond = cond\n",
    "            best_J_pinv = np.linalg.pinv(J_stack)  # shape (8, 3*k)\n",
    "            best_k = k\n",
    "\n",
    "        # if full-rank AND well-conditioned enough, stop and return\n",
    "        if np.isfinite(cond) and rank == n_cols and cond <= cond_threshold:\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"✅ Reached full rank (8) and desired conditioning: \"\n",
    "                    f\"rank = {rank}, cond = {cond:.3e} ≤ {cond_threshold:.3e}\"\n",
    "                )\n",
    "            J_stack_final = np.vstack(J_blocks[:best_k])      # (3*best_k, 8)\n",
    "            b_stack_final = np.concatenate(b_blocks[:best_k]) # (3*best_k,)\n",
    "            return best_J_pinv, best_cond, best_k, J_stack_final, b_stack_final\n",
    "\n",
    "    # If we get here, we never reached full-rank & good cond within max_num_samples\n",
    "    if best_J_pinv is None:\n",
    "        print(\n",
    "            f\"⚠️ Never achieved full column rank 8 within {max_num_samples} samples. \"\n",
    "            f\"No valid pseudo-inverse returned.\"\n",
    "        )\n",
    "        return None, np.inf, 0, None, None\n",
    "\n",
    "    print(\n",
    "        f\"⚠️ Did not reach cond <= {cond_threshold:.3e} \"\n",
    "        f\"within {max_num_samples} samples, but best full-rank cond = {best_cond:.3e} at k={best_k}.\"\n",
    "    )\n",
    "    J_stack_final = np.vstack(J_blocks[:best_k])      # (3*best_k, 8)\n",
    "    b_stack_final = np.concatenate(b_blocks[:best_k]) # (3*best_k,)\n",
    "    return best_J_pinv, best_cond, best_k, J_stack_final, b_stack_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb942a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "J_pinv, cond_final, k_used, J_stack, b_stack = build_well_conditioned_stack(\n",
    "    data=data,\n",
    "    affine_model=model,\n",
    "    max_num_samples=100,\n",
    "    cond_threshold=5.0,\n",
    "    seed=4,\n",
    ")\n",
    "\n",
    "print(\"Final cond:\", cond_final)\n",
    "print(\"Samples used:\", k_used)\n",
    "print(\"J_pinv shape:\", None if J_pinv is None else J_pinv.shape)\n",
    "\n",
    "if J_pinv is not None:\n",
    "    # currents that reproduce the bias\n",
    "    I_equiv = J_pinv @ b_stack          # shape (8,)\n",
    "\n",
    "    print(\"Equivalent currents (A) that reproduce b:\", I_equiv)\n",
    "\n",
    "    # sanity check relative residual\n",
    "    res = J_stack @ I_equiv - b_stack   # (3*k,)\n",
    "    rel_res = np.linalg.norm(res) / np.linalg.norm(b_stack)\n",
    "    print(\"Relative residual ||J I_equiv - b|| / ||b|| =\", rel_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5323c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiple_stacks(\n",
    "    data,\n",
    "    affine_model,\n",
    "    n_runs: int = 10,\n",
    "    max_num_samples: int = 50,\n",
    "    cond_threshold: float = 5.0,\n",
    "    min_samples: int = 3,\n",
    "    svd_tol: float = 1e-8,\n",
    "    seed: int = 0,\n",
    "    verbose: bool = True,\n",
    "    store_matrices: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run build_well_conditioned_stack multiple times with a *single* RNG seed,\n",
    "    collecting results into a DataFrame.\n",
    "\n",
    "    For each run we store:\n",
    "      - best_cond       : condition number of best stack\n",
    "      - k_used          : number of samples used\n",
    "      - success         : whether a valid pseudo-inverse was found\n",
    "      - em_0,...        : estimated equivalent currents per coil\n",
    "      - res_norm        : ||J_stack I_equiv - b_stack||\n",
    "      - rel_res         : ||J_stack I_equiv - b_stack|| / ||b_stack||\n",
    "\n",
    "    Optionally also store the matrices themselves.\n",
    "    \"\"\"\n",
    "\n",
    "    rng = np.random.default_rng(seed)  # single generator\n",
    "\n",
    "    # Coil column names (in desired order)\n",
    "    coil_cols = [\"em_0\", \"em_1\", \"em_2\", \"em_3\", \"em_4\", \"em_5\", \"em_7\", \"em_8\"]\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for run_id in range(n_runs):\n",
    "        J_pinv, cond, k_used, J_stack, b_stack = build_well_conditioned_stack(\n",
    "            data=data,\n",
    "            affine_model=affine_model,\n",
    "            max_num_samples=max_num_samples,\n",
    "            cond_threshold=cond_threshold,\n",
    "            min_samples=min_samples,\n",
    "            svd_tol=svd_tol,\n",
    "            seed=rng,           # pass generator, not int\n",
    "            verbose=verbose,\n",
    "        )\n",
    "\n",
    "        # Base row\n",
    "        row = {\n",
    "            \"run_id\": run_id,\n",
    "            \"max_num_samples\": max_num_samples,\n",
    "            \"cond_threshold\": cond_threshold,\n",
    "            \"min_samples\": min_samples,\n",
    "            \"svd_tol\": svd_tol,\n",
    "            \"best_cond\": cond,\n",
    "            \"k_used\": k_used,\n",
    "            \"success\": (J_pinv is not None),\n",
    "            \"res_norm\": np.nan,\n",
    "            \"rel_res\": np.nan,\n",
    "        }\n",
    "\n",
    "        # Initialize coil columns as NaN\n",
    "        for col in coil_cols:\n",
    "            row[col] = np.nan\n",
    "\n",
    "        if J_pinv is not None and J_stack is not None and b_stack is not None:\n",
    "            # Equivalent currents that reproduce the stacked bias\n",
    "            I_equiv = J_pinv @ b_stack        # (num_coils,)\n",
    "\n",
    "            # Fill coil columns in order\n",
    "            n_coils = min(len(coil_cols), len(I_equiv))\n",
    "            for i in range(n_coils):\n",
    "                row[coil_cols[i]] = float(I_equiv[i])\n",
    "\n",
    "            # Residuals\n",
    "            res = J_stack @ I_equiv - b_stack # (3*k_used,)\n",
    "            res_norm = float(np.linalg.norm(res))\n",
    "            b_norm = float(np.linalg.norm(b_stack))\n",
    "            rel_res = res_norm / b_norm if b_norm > 0 else np.nan\n",
    "\n",
    "            row[\"res_norm\"] = res_norm\n",
    "            row[\"rel_res\"] = rel_res\n",
    "\n",
    "        if store_matrices:\n",
    "            row[\"J_pinv\"] = J_pinv\n",
    "            row[\"J_stack\"] = J_stack\n",
    "            row[\"b_stack\"] = b_stack\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263b9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_runs = run_multiple_stacks(\n",
    "    data=data,\n",
    "    affine_model=model,\n",
    "    n_runs=50,\n",
    "    max_num_samples=50,\n",
    "    cond_threshold=5.0,\n",
    "    min_samples=3,\n",
    "    svd_tol=1e-8,\n",
    "    seed=42,\n",
    "    verbose=False,\n",
    "    store_matrices=False,\n",
    ")\n",
    "\n",
    "df_runs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9eae17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_stack_boxplots_with_currents(df, figsize=(10, 6), title=None):\n",
    "    \"\"\"\n",
    "    Top row: boxplots for best_cond, k_used, res_norm (shared y-range).\n",
    "    Bottom row: boxplots for em_* columns (one axis, separate y-scale).\n",
    "    \"\"\"\n",
    "    metrics = [\"best_cond\", \"k_used\", \"res_norm\"]\n",
    "    data_metrics = [df[m].dropna().to_numpy() for m in metrics]\n",
    "\n",
    "    # em_* columns\n",
    "    em_cols = [col for col in df.columns if col.startswith(\"em_\")]\n",
    "    em_data = [df[c].dropna().to_numpy() for c in em_cols]\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, constrained_layout=True)\n",
    "    gs = fig.add_gridspec(2, 3)\n",
    "\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=14)\n",
    "\n",
    "    # ---- Top row: metrics ----\n",
    "    axes_metrics = []\n",
    "    for i, (m, vals) in enumerate(zip(metrics, data_metrics)):\n",
    "        ax = fig.add_subplot(gs[0, i])\n",
    "        ax.boxplot(vals, showfliers=False)\n",
    "        ax.set_title(m)\n",
    "        ax.set_xticks([])\n",
    "        if i == 0:\n",
    "            ax.set_ylabel(\"Value\")\n",
    "        axes_metrics.append(ax)\n",
    "\n",
    "    # ---- Bottom row: em_* currents ----\n",
    "    ax_em = fig.add_subplot(gs[1, :])   # span all columns\n",
    "\n",
    "    if em_cols:\n",
    "        ax_em.boxplot(em_data, labels=em_cols, showfliers=False)\n",
    "        ax_em.set_ylabel(\"Equivalent current (A)\")\n",
    "        ax_em.set_title(\"Estimated equivalent currents per coil\")\n",
    "        ax_em.tick_params(axis=\"x\", rotation=30)\n",
    "    else:\n",
    "        ax_em.text(0.5, 0.5, \"No em_* columns found\", ha=\"center\", va=\"center\")\n",
    "        ax_em.set_axis_off()\n",
    "\n",
    "    plt.show()\n",
    "    return fig, axes_metrics, ax_em\n",
    "\n",
    "fig, axes_metrics, ax_em = plot_stack_boxplots_with_currents(\n",
    "    df_runs,\n",
    "    title=\"Stack selection + equivalent currents\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
