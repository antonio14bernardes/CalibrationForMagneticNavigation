{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1cc61b",
   "metadata": {},
   "source": [
    "# Training Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513a311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "base_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "src_dir = base_dir + \"/src\"\n",
    "\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "\n",
    "from calibration import DirectGBT\n",
    "from data_analysis import plot_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "########### Which eMNS? ###########\n",
    "###################################\n",
    "\n",
    "emns = \"octomag\" # \"octomag\" or \"navion\"\n",
    "if emns == \"octomag\":\n",
    "    data_dir = base_dir + \"/data/octomag_data/split_dataset/\"\n",
    "    store_model_dir = cwd + \"/trees/\"\n",
    "if emns == \"navion\":\n",
    "    data_dir = base_dir + \"/data/navion_data/split_dataset/\"\n",
    "    store_model_dir = cwd + \"/navion_trees/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb9697",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14363b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_percentage = 100 # percent of the training/validation dataset to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e02bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_name = data_dir + [f\"training_data_{dataset_percentage}.pkl\" if dataset_percentage != 100 else \"training_data.pkl\"][0]\n",
    "validation_data_name = data_dir + [f\"validation_data_{dataset_percentage}.pkl\" if dataset_percentage != 100 else \"validation_data.pkl\"][0]\n",
    "training_data = pd.read_pickle(training_data_name)\n",
    "validation_data = pd.read_pickle(validation_data_name)\n",
    "test_data = pd.read_pickle(data_dir + \"test_data.pkl\")\n",
    "\n",
    "em_cols = [col for col in training_data.columns if col.startswith(\"em_\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7160d3",
   "metadata": {},
   "source": [
    "### Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a90916",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d = True\n",
    "plot_distributions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525ce2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_3d:\n",
    "    plot_positions(training_data, title=\"Training Data Positions Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88394a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_3d:\n",
    "    plot_positions(validation_data, title=\"Validation Data Positions Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea0cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_3d:\n",
    "    plot_positions(test_data, title=\"Test Data Positions Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f56cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_distributions:\n",
    "    features_to_plot = [\"Bx\", \"By\", \"Bz\", \"x\", \"y\", \"z\"]\n",
    "\n",
    "    n = len(features_to_plot)\n",
    "    ncols = 3\n",
    "    nrows = math.ceil(n / ncols)   # will be 2\n",
    "\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(5*ncols, 3.5*nrows), squeeze=False)\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    for i, feature in enumerate(features_to_plot):\n",
    "        ax = axes[i]\n",
    "        ax.hist(training_data[feature], bins=50, alpha=0.5, label=\"Train\", density=True)\n",
    "        ax.hist(validation_data[feature], bins=50, alpha=0.5, label=\"Val\", density=True)\n",
    "        ax.hist(test_data[feature], bins=50, alpha=0.5, label=\"Test\", density=True)\n",
    "        ax.set_title(feature)\n",
    "        ax.set_xlabel(feature)\n",
    "        ax.set_ylabel(\"Density\")\n",
    "\n",
    "    # shared legend\n",
    "    handles, labels = axes[0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc=\"upper right\", frameon=True)\n",
    "\n",
    "    fig.suptitle(\"Distributions (Train / Val / Test)\", y=1.02)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dc67e5",
   "metadata": {},
   "source": [
    "## Parameters for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfd2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should we normalize?\n",
    "normalize_targets = True\n",
    "normalize_position = False\n",
    "\n",
    "# GBT hyperparameters\n",
    "n_estimators = 5000\n",
    "learning_rate = 0.1\n",
    "num_leaves = 128\n",
    "min_child_samples = 20\n",
    "subsample = 1.0\n",
    "colsample_bytree = 1.0\n",
    "random_state = 2\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_patience = 200\n",
    "\n",
    "\n",
    "# Bothering\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee20645",
   "metadata": {},
   "source": [
    "## Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960ae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DirectGBT(\n",
    "    name = \"DirectGBT_\" + str(dataset_percentage) + \"_\" + str(num_leaves),\n",
    "    current_names = em_cols\n",
    ")\n",
    "\n",
    "model.train(\n",
    "    # Data\n",
    "    train_df = training_data,\n",
    "    val_df = validation_data,\n",
    "    \n",
    "    # Normalize\n",
    "    normalize_targets = normalize_targets,\n",
    "    normalize_position = normalize_position,\n",
    "\n",
    "    # Hyperparameters\n",
    "    n_estimators = n_estimators,\n",
    "    learning_rate = learning_rate,\n",
    "    num_leaves = num_leaves,\n",
    "    min_child_samples = min_child_samples,\n",
    "    subsample = subsample,\n",
    "    colsample_bytree = colsample_bytree,\n",
    "    random_state = random_state,\n",
    "\n",
    "    # Early stopping\n",
    "    early_stopping_patience = early_stopping_patience,\n",
    "    \n",
    "    # Yap\n",
    "    verbose = verbose\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec818d36",
   "metadata": {},
   "source": [
    "## Test trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf87779e",
   "metadata": {},
   "source": [
    "### Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cef733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on test set\n",
    "position_test = test_data[[\"x\", \"y\", \"z\"]].to_numpy()\n",
    "currents_test = test_data[em_cols].to_numpy()\n",
    "targets_test  = test_data[[\"Bx\", \"By\", \"Bz\"]].to_numpy()\n",
    "\n",
    "predictions_test = model.predict_targets(position=position_test, currents=currents_test)\n",
    "\n",
    "# Error matrix\n",
    "error = predictions_test - targets_test\n",
    "\n",
    "# Overall error norm (Frobenius)\n",
    "rse = np.linalg.norm(error, axis=1)            # scalar\n",
    "\n",
    "# Per-sample magnitudes\n",
    "mag_t = np.linalg.norm(targets_test, axis=1)        # (N,)\n",
    "mag_p = np.linalg.norm(predictions_test, axis=1)    # (N,)\n",
    "\n",
    "# Relative magnitude error (per-sample), safe for mag_t == 0\n",
    "eps = 1e-3\n",
    "magnitude_rel_error = np.abs((mag_p - mag_t) / np.maximum(mag_t, eps))  # (N,)\n",
    "\n",
    "# Angle error (per-sample), safe for zero magnitudes\n",
    "dot = np.sum(predictions_test * targets_test, axis=1)                  # (N,)\n",
    "cosang = dot / (np.maximum(mag_p, eps) * np.maximum(mag_t, eps))        # (N,)\n",
    "angle_error = np.arccos(np.clip(cosang, -1.0, 1.0))                     # radians (N,)\n",
    "\n",
    "# Optional: degrees\n",
    "angle_error_deg = np.degrees(angle_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45943b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot error distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Box plot for RSE, Magnitude Relative Error, Angle Error\n",
    "axes[0].boxplot(rse, vert=True, showfliers=False)\n",
    "axes[0].set_title(\"RSE Distribution\")\n",
    "axes[0].set_ylabel(\"RSE (T)\")\n",
    "axes[1].boxplot(magnitude_rel_error, vert=True, showfliers=False)\n",
    "axes[1].set_title(\"Magnitude Relative Error Distribution\")\n",
    "axes[1].set_ylabel(\"Relative Error\")\n",
    "axes[2].boxplot(angle_error_deg, vert=True, showfliers=False)\n",
    "axes[2].set_title(\"Angle Error Distribution\")   \n",
    "axes[2].set_ylabel(\"Angle Error (degrees)\")\n",
    "fig.suptitle(\"Test Set Error Distributions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe29072",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on test set\n",
    "position_train = training_data[[\"x\", \"y\", \"z\"]].to_numpy()\n",
    "currents_train = training_data[em_cols].to_numpy()\n",
    "targets_train  = training_data[[\"Bx\", \"By\", \"Bz\"]].to_numpy()\n",
    "\n",
    "predictions_train = model.predict_targets(position=position_train, currents=currents_train)\n",
    "\n",
    "# Error matrix\n",
    "error = predictions_train - targets_train\n",
    "\n",
    "# Overall error norm (Frobenius)\n",
    "rse = np.linalg.norm(error, axis=1)            # scalar\n",
    "\n",
    "# Per-sample magnitudes\n",
    "mag_t = np.linalg.norm(targets_train, axis=1)        # (N,)\n",
    "mag_p = np.linalg.norm(predictions_train, axis=1)    # (N,)\n",
    "\n",
    "# Relative magnitude error (per-sample), safe for mag_t == 0\n",
    "eps = 1e-3\n",
    "magnitude_rel_error = np.abs((mag_p - mag_t) / np.maximum(mag_t, eps))  # (N,)\n",
    "\n",
    "# Angle error (per-sample), safe for zero magnitudes\n",
    "dot = np.sum(predictions_train * targets_train, axis=1)                  # (N,)\n",
    "cosang = dot / (np.maximum(mag_p, eps) * np.maximum(mag_t, eps))        # (N,)\n",
    "angle_error = np.arccos(np.clip(cosang, -1.0, 1.0))                     # radians (N,)\n",
    "\n",
    "# Optiondegrees\n",
    "angle_error_deg = np.degrees(angle_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2035726f",
   "metadata": {},
   "source": [
    "### Compare training set performance with test set performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd407b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_df(df, em_cols, model, eps=1e-9):\n",
    "    \"\"\"\n",
    "    Returns per-sample metrics + scalar RMSE for one dataframe.\n",
    "    Assumes df has columns: x,y,z, em_*, Bx,By,Bz\n",
    "    \"\"\"\n",
    "    pos = df[[\"x\", \"y\", \"z\"]].to_numpy()\n",
    "    cur = df[em_cols].to_numpy()\n",
    "    tgt = df[[\"Bx\", \"By\", \"Bz\"]].to_numpy()\n",
    "\n",
    "    pred = model.predict_targets(position=pos, currents=cur)\n",
    "\n",
    "    err = pred - tgt\n",
    "    rse = np.linalg.norm(err, axis=1)  # (N,) |error| in field units\n",
    "\n",
    "    mag_t = np.linalg.norm(tgt, axis=1)\n",
    "    mag_p = np.linalg.norm(pred, axis=1)\n",
    "\n",
    "    mag_rel_err = np.abs(mag_p - mag_t) / np.maximum(mag_t, eps)\n",
    "\n",
    "    dot = np.sum(pred * tgt, axis=1)\n",
    "    cosang = dot / (np.maximum(mag_p, eps) * np.maximum(mag_t, eps))\n",
    "    angle_err = np.arccos(np.clip(cosang, -1.0, 1.0))\n",
    "    angle_err_deg = np.degrees(angle_err)\n",
    "\n",
    "    rmse = np.sqrt(np.mean(rse**2))\n",
    "\n",
    "    return {\n",
    "        \"pred\": pred,\n",
    "        \"tgt\": tgt,\n",
    "        \"err\": err,\n",
    "        \"rse\": rse,\n",
    "        \"mag_rel_err\": mag_rel_err,\n",
    "        \"angle_err_deg\": angle_err_deg,\n",
    "        \"rmse\": rmse,\n",
    "    }\n",
    "\n",
    "# --- Evaluate TRAIN vs TEST (fixes your bug: train uses training_data, not test_data) ---\n",
    "print(\"Eval train data\")\n",
    "train_metrics = eval_df(training_data, em_cols, model, eps=1e-9)\n",
    "print(\"Eval test data\")\n",
    "test_metrics  = eval_df(test_data,     em_cols, model, eps=1e-9)\n",
    "\n",
    "print(f\"Train RMSE: {train_metrics['rmse']:.6g}\")\n",
    "print(f\"Test  RMSE: {test_metrics['rmse']:.6g}\")\n",
    "\n",
    "# --- Plot: boxplot of RSE (left) + RMSE bars (right) ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8.0, 3.2), constrained_layout=True)\n",
    "\n",
    "# Left: RSE distributions\n",
    "axes[0].boxplot(\n",
    "    [train_metrics[\"rse\"], test_metrics[\"rse\"]],\n",
    "    labels=[\"Train\", \"Test\"],\n",
    "    showfliers=False\n",
    ")\n",
    "axes[0].set_title(\"RSE distribution\")\n",
    "axes[0].set_ylabel(\"RSE (field units)\")  # change to mT or T if you know for sure\n",
    "\n",
    "# Right: RMSE bars\n",
    "axes[1].bar([\"Train\", \"Test\"], [train_metrics[\"rmse\"], test_metrics[\"rmse\"]])\n",
    "axes[1].set_title(\"RMSE\")\n",
    "axes[1].set_ylabel(\"RMSE (field units)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5ff8f3",
   "metadata": {},
   "source": [
    "# Store the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78129021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(store_model_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
