{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d485d2ed",
   "metadata": {},
   "source": [
    "# Ransac experiment per coil and per position. We are fiting the ransac model to the affinity in currents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c13d7",
   "metadata": {},
   "source": [
    "# Note for reviewer:\n",
    "\n",
    "A small error in this notebook was found during cleanup such that the percentage of outliers detected in the OctoMag dataset reported in the paper is slightly wrong. The corrected value will be updated in the revision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c0b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "\n",
    "\n",
    "cwd = os.getcwd()\n",
    "parent_dir = os.path.dirname(cwd)\n",
    "base_dir = os.path.dirname(parent_dir)\n",
    "\n",
    "\n",
    "src_dir = base_dir + \"/src\"\n",
    "\n",
    "sys.path.insert(0, src_dir)\n",
    "\n",
    "from data_analysis import data_processing, load_data, convert_frames, correct_sensor_bias, plot_quiver_slice, load_navion_format, plot_positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0a481c",
   "metadata": {},
   "source": [
    "## Select which eMNS dataset to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aebf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "########### Which eMNS? #############\n",
    "#####################################\n",
    "emns = \"octomag\" # \"octomag\" or \"navion\"\n",
    "\n",
    "if emns.lower() == \"octomag\":\n",
    "    data_dir = base_dir + \"/data/octomag_data/data\"\n",
    "    sensor_bias_file = data_dir + \"/sensor_bias.csv\"\n",
    "\n",
    "    clean_data_dir = base_dir + \"/data/octomag_data/clean_data\"\n",
    "    processed_data_file = clean_data_dir + \"/outlier_data_currents.pkl\"\n",
    "    clean_data_file = clean_data_dir + \"/clean_data.pkl\"\n",
    "\n",
    "    data_og = convert_frames(correct_sensor_bias(load_data(data_dir), bias_csv=sensor_bias_file))\n",
    "\n",
    "elif emns.lower() == \"navion\":\n",
    "    data_dir = base_dir + \"/data/navion_data/data\"\n",
    "    clean_data_dir = data_dir + \"/../clean_data\"\n",
    "    processed_data_file = clean_data_dir + \"/outlier_data_currents.pkl\"\n",
    "    clean_data_file = clean_data_dir + \"/clean_data.pkl\"\n",
    "    data_og = convert_frames(load_navion_format(data_dir))\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"eMNS type not recognized. Please use 'octomag' or 'navion'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b653b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the magnitudes of the original dataset. Draw vertical lines for quartiles\n",
    "plt.figure(figsize=(8, 5))\n",
    "magnitudes = np.linalg.norm(data_og[[\"Bx\", \"By\", \"Bz\"]].to_numpy(), axis=1)\n",
    "plt.hist(magnitudes, bins=50, edgecolor='black')\n",
    "\n",
    "# Calculate quartiles\n",
    "quartiles = np.percentile(magnitudes, [25, 50, 75])\n",
    "for q in quartiles:\n",
    "    plt.axvline(q, color='r', linestyle='dashed', linewidth=1)\n",
    "\n",
    "plt.xlabel(\"Magnetic Field Magnitude (mT)\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.title(\"Histogram of Magnetic Field Magnitudes. Quartiles marked in red dashed lines.\")\n",
    "plt.show()\n",
    "\n",
    "# print the quartile values\n",
    "print(\"Quartiles of Magnetic Field Magnitudes (mT):\")\n",
    "print(f\"25th percentile: {quartiles[0]:.4f} mT\")\n",
    "print(f\"50th percentile (median): {quartiles[1]:.4f} mT\")\n",
    "print(f\"75th percentile: {quartiles[2]:.4f} mT\")\n",
    "\n",
    "# Store first quartile\n",
    "first_quartile = quartiles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ab53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_og\n",
    "total_data_points = len(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943be4ba",
   "metadata": {},
   "source": [
    "## Create a key to identify different positions\n",
    "\n",
    "Consider coordinates as the same if they are within a threshold of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 0.002 if emns.lower() == \"navion\" else 0.0016  \n",
    "cols = ['x', 'y', 'z']\n",
    "\n",
    "# Create a discrete key representing each tolerance-sized cell\n",
    "df_key = (data[cols] / tol).round().astype(int)\n",
    "\n",
    "# Turn that into a single string key per row\n",
    "data['pos_key'] = df_key.astype(str).agg('_'.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b0e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print number of unique positions\n",
    "unique_positions = data['pos_key'].nunique()\n",
    "print(f\"Number of unique positions (within {tol*1000} mm tolerance): {unique_positions}\")\n",
    "\n",
    "# Stats on number of samples per position\n",
    "samples_per_position = data['pos_key'].value_counts()\n",
    "print(\"Samples per position stats:\")\n",
    "print(samples_per_position.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873d36bc",
   "metadata": {},
   "source": [
    "## Also separate by active coil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f6d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "em_cols = [col for col in data.columns if col.startswith('em_')]\n",
    "\n",
    "candidate = data[em_cols].abs().idxmax(axis=1)\n",
    "\n",
    "data['active_coil'] = candidate.where(data[em_cols].ne(0).any(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217a8d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rows with no active coil are NaN in 'active_coil' column\n",
    "# Lets repeat each of these rows for each coil\n",
    "has_coil = data['active_coil'].notna()\n",
    "data_with = data[has_coil].copy()\n",
    "data_without = data[~has_coil].copy()   # these have all em_* = 0\n",
    "\n",
    "repeated = pd.concat(\n",
    "    [data_without.assign(active_coil=coil) for coil in em_cols],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "data_expanded = pd.concat([data_with, repeated], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286322e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the active coil to the key\n",
    "data_expanded['pos_coil_key'] = data_expanded['pos_key'] + '_'  + data_expanded['active_coil']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280685d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = data_expanded['pos_coil_key'].unique()\n",
    "print(f\"Number of unique position+coil keys: {len(keys)}\")\n",
    "\n",
    "# Number of samples per key\n",
    "samples_per_key = data_expanded['pos_coil_key'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee1811",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples = 5\n",
    "small_counts = samples_per_key[samples_per_key < min_samples]\n",
    "\n",
    "bad_keys = small_counts.index\n",
    "\n",
    "# Set a bad key flag\n",
    "data_expanded['bad_key'] = data_expanded['pos_coil_key'].isin(bad_keys)\n",
    "\n",
    "data_good = data_expanded[~data_expanded['bad_key']].copy()\n",
    "\n",
    "del data_expanded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c7db04",
   "metadata": {},
   "source": [
    "## Now run a RANSAC affine regression per position + active coil (should be an affine mapping from current to field)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d2352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_one_group(\n",
    "    df_group,\n",
    "    min_distinct_currents=3,\n",
    "    residual_percent=20.0,   # allowed error (%)\n",
    "    max_trials=100,\n",
    "    min_abs_threshold=3.27 if emns.lower() == \"navion\" else 2.66,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run RANSAC for a single pos_coil_key group using a *relative* L2 vector loss.\n",
    "\n",
    "    Model:\n",
    "      B(I) = a * I + b, B in R^3 (Bx, By, Bz)\n",
    "\n",
    "    Residual per sample i:\n",
    "      e_i    = ||B_meas_i - B_pred_i||_2\n",
    "      Bmag_i = ||B_meas_i||\n",
    "\n",
    "      denom_i = max(Bmag_i, min_abs_threshold)\n",
    "      rel_i   = e_i / denom_i   (dimensionless relative error)\n",
    "\n",
    "    RANSAC inlier condition:\n",
    "      rel_i <= residual_percent / 100\n",
    "    \"\"\"\n",
    "\n",
    "    df = df_group\n",
    "\n",
    "    field_cols = [\"Bx\", \"By\", \"Bz\"]\n",
    "    current_col = df[\"active_coil\"].iloc[0]  # e.g. \"em_0\", ...\n",
    "\n",
    "    # Drop exact duplicates (same current + same field). Sort for reproducibility\n",
    "    subset_cols = [current_col] + field_cols\n",
    "    df = df.drop_duplicates(subset=subset_cols)\n",
    "\n",
    "    # Extract arrays\n",
    "    currents = df[current_col].to_numpy()\n",
    "    B = df[field_cols].to_numpy()  # (n_samples, 3)\n",
    "    n_points = len(df)\n",
    "    n_distinct_currents = np.unique(currents).shape[0]\n",
    "\n",
    "    # Init bookkeeping columns\n",
    "    df[\"ransac_fit_ok\"] = False\n",
    "    df[\"ransac_n_points\"] = n_points\n",
    "    df[\"ransac_n_inliers\"] = 0\n",
    "    df[\"ransac_inlier\"] = False\n",
    "\n",
    "    for name in [\"ransac_slope_x\", \"ransac_slope_y\", \"ransac_slope_z\",\n",
    "                 \"ransac_offset_x\", \"ransac_offset_y\", \"ransac_offset_z\"]:\n",
    "        df[name] = np.nan\n",
    "\n",
    "    # Not enough distinct currents → can't fit reliably\n",
    "    if n_distinct_currents < min_distinct_currents:\n",
    "        df[\"outlier_in_currents\"] = True\n",
    "        df[\"ransac_residual_norm\"] = np.nan\n",
    "        df[\"ransac_residual_rel\"] = np.nan\n",
    "        df[\"ransac_vector_outlier\"] = True\n",
    "        return df\n",
    "\n",
    "    # Field magnitude in this group\n",
    "    B_mag = np.linalg.norm(B, axis=1)\n",
    "\n",
    "    \n",
    "\n",
    "    # Relative threshold \n",
    "    residual_threshold_rel = residual_percent / 100.0\n",
    "\n",
    "    # Prepare data for sklearn\n",
    "    X = currents.reshape(-1, 1)  # (n_samples, 1)\n",
    "    y = B                        # (n_samples, 3)\n",
    "\n",
    "    base_model = LinearRegression(fit_intercept=True)\n",
    "\n",
    "    # --- custom relative L2 loss ---\n",
    "    def rel_l2_loss(y_true, y_pred, min_abs_threshold=min_abs_threshold):\n",
    "        diff = y_true - y_pred\n",
    "        num = np.linalg.norm(diff, axis=1)      # ||ΔB||\n",
    "        Bmag = np.linalg.norm(y_true, axis=1)   # ||B||\n",
    "        denom = np.maximum(Bmag, min_abs_threshold)   # elementwise max\n",
    "\n",
    "        return num / denom                      # relative error per sample\n",
    "\n",
    "    ransac = RANSACRegressor(\n",
    "        estimator=base_model,\n",
    "        min_samples=2,\n",
    "        loss=rel_l2_loss,\n",
    "        residual_threshold=residual_threshold_rel,\n",
    "        max_trials=max_trials,\n",
    "        random_state=0,\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        ransac.fit(X, y)\n",
    "    except Exception as e:\n",
    "        print(f\"RANSAC failed for group {df['pos_coil_key'].iloc[0]}: {e}\")\n",
    "        df[\"outlier_in_currents\"] = True\n",
    "        df[\"ransac_residual_norm\"] = np.nan\n",
    "        df[\"ransac_residual_rel\"] = np.nan\n",
    "        df[\"ransac_vector_outlier\"] = True\n",
    "        return df\n",
    "\n",
    "    inlier_mask = ransac.inlier_mask_\n",
    "    n_inliers = int(inlier_mask.sum())\n",
    "\n",
    "    df.loc[df.index, \"ransac_inlier\"] = inlier_mask\n",
    "    df[\"ransac_fit_ok\"] = True\n",
    "    df[\"ransac_n_inliers\"] = n_inliers\n",
    "\n",
    "    # Slopes and offsets\n",
    "    est = ransac.estimator_\n",
    "    slopes = est.coef_.reshape(-1)\n",
    "    offsets = est.intercept_.reshape(-1)\n",
    "\n",
    "    df[\"ransac_slope_x\"] = slopes[0]\n",
    "    df[\"ransac_slope_y\"] = slopes[1]\n",
    "    df[\"ransac_slope_z\"] = slopes[2]\n",
    "    df[\"ransac_offset_x\"] = offsets[0]\n",
    "    df[\"ransac_offset_y\"] = offsets[1]\n",
    "    df[\"ransac_offset_z\"] = offsets[2]\n",
    "\n",
    "    # For diagnostics: absolute + relative residuals for the final model\n",
    "    y_pred = ransac.predict(X)\n",
    "    res_vec = y - y_pred\n",
    "    res_norm = np.linalg.norm(res_vec, axis=1)\n",
    "\n",
    "    denom = np.maximum(B_mag, min_abs_threshold)\n",
    "    res_rel = res_norm / denom\n",
    "\n",
    "    df[\"ransac_residual_norm\"] = res_norm\n",
    "    df[\"ransac_residual_rel\"] = res_rel\n",
    "\n",
    "    # Make main label consistent with that\n",
    "    df[\"outlier\"] = ~df[\"ransac_inlier\"]  \n",
    "        \n",
    "    # Add current column\n",
    "    df[\"current\"] = currents\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa955c8",
   "metadata": {},
   "source": [
    "### Apply RANSAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4492935",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = data_good.groupby(\"pos_coil_key\")\n",
    "n_groups = len(groups)\n",
    "\n",
    "results = []\n",
    "for key, group in tqdm(groups, total=n_groups, desc=\"RANSAC per pos_coil_key\"):\n",
    "    results.append(ransac_one_group(group, min_abs_threshold=first_quartile))\n",
    "\n",
    "del data_good\n",
    "\n",
    "print(\"Concatenating results, this may take a while...\")\n",
    "data_ransac = pd.concat(results, ignore_index=True)\n",
    "print(\"Done RANSAC processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5b1c68",
   "metadata": {},
   "source": [
    "### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d086844",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_outliers = data_ransac[\"outlier\"].sum()\n",
    "print(f\"Total number of outlier samples detected by RANSAC: {num_outliers}, out of {len(data_ransac)} total samples. Corresponding to {num_outliers/len(data_ransac)*100:.2f}% of the dataset.\")\n",
    "\n",
    "outlier_df = data_ransac[data_ransac[\"outlier\"]]\n",
    "\n",
    "# Calculate magnetic field magnitude for outliers\n",
    "B_magnitude = np.linalg.norm(outlier_df[[\"Bx\", \"By\", \"Bz\"]].to_numpy(), axis=1)\n",
    "\n",
    "# Plot count of outliers against magnetic field magnitude\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(B_magnitude, bins=100, edgecolor='black')\n",
    "plt.xlabel(\"Magnetic Field Magnitude (mT)\")\n",
    "plt.ylabel(\"Number of Outlier Samples\")\n",
    "plt.title(\"Distribution of Outlier Samples vs Magnetic Field Magnitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d764e",
   "metadata": {},
   "source": [
    "## Save the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep \n",
    "keep_cols = [\"x\", \"y\", \"z\", \"Bx\", \"By\", \"Bz\"] + \\\n",
    "            em_cols + \\\n",
    "             (['lvl', 'pos', 'rot', 'base_x', 'base_y', 'z_offset'] if emns.lower() == \"octomag\" else [])\n",
    "\n",
    "ransac_cols = [\"ransac_slope_x\", \"ransac_slope_y\", \"ransac_slope_z\",\n",
    "             \"ransac_offset_x\", \"ransac_offset_y\", \"ransac_offset_z\",\n",
    "             \"ransac_residual_norm\", \"ransac_residual_rel\",\n",
    "             \"ransac_inlier\", \"ransac_fit_ok\",\n",
    "             \"ransac_n_points\", \"ransac_n_inliers\", \"outlier\",\n",
    "             \"active_coil\", \"current\"]\n",
    "\n",
    "\n",
    "data_keep = data_ransac[keep_cols + ransac_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce068e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make dir if not exists\n",
    "os.makedirs(clean_data_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Saving cleaned data to {processed_data_file}...\")\n",
    "\n",
    "data_keep.to_pickle(processed_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ca48e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = data_keep[~data_keep[\"outlier\"]].copy()\n",
    "data_clean = data_clean[keep_cols]\n",
    "data_clean.drop_duplicates(inplace=True)\n",
    "\n",
    "\n",
    "print(f\"Saving final clean data to {clean_data_file}...\")\n",
    "data_clean.to_pickle(clean_data_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
